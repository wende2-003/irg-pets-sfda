[02/24 01:03:16] detectron2 INFO: Rank of current process: 0. World size: 1
[02/24 01:03:17] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:51:32) [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
numpy                   1.19.5
detectron2              0.6 @/root/irg-sfda/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu102 @/root/miniconda3/envs/irg_sfda/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
Driver version          550.90.07
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.0+cu102 @/root/miniconda3/envs/irg_sfda/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.3
----------------------  ---------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/24 01:03:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sfda/sfda_foggy.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, model_dir='/root/autodl-tmp/model_final.pth', num_gpus=1, num_machines=1, opts=[], resume=False)
[02/24 01:03:17] detectron2 INFO: Contents of args.config_file=configs/sfda/sfda_foggy.yaml:
MODEL:
  META_ARCHITECTURE: "student_sfda_RCNN"
  WEIGHT: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: False
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 300
    ANCHOR_SIZES: (128, 256, 512)
  ROI_HEADS:
    NUM_CLASSES: 8
  RESNETS:
    NORM: "FrozenBN" 
    OUT_FEATURES: ["res4"]
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MIN_SIZE_TEST: 600
DATASETS:
  TRAIN: ("cityscape_2007_train_t",)
  TEST: ("cityscape_2007_test_t",)
SOLVER:
  BASE_LR: 0.0001
  WEIGHT_DECAY: 0.0001
  STEPS: ()
  MAX_ITER: 70000
  IMS_PER_BATCH: 1
  WARMUP_ITERS: 1000
  CHECKPOINT_PERIOD: 5000
TEST:
  EVAL_PERIOD: 2000
SOURCE_FREE:
  TYPE: True
  MODE: True
  PETS:
    ENABLED: True
    EXCHANGE_PERIOD: 3
    EMA_KEEP_RATE: 0.999
    CONF_THRESH: 0.6
    IOU_THRESH: 0.5
    BETA: 0.5
    EPOCH_ITERS: 0
    TOTAL_EPOCHS: 10
    WARMUP_EPOCHS: 4
OUTPUT_DIR: "./checkpoint/foggy"

[02/24 01:03:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - cityscape_2007_test_t
  TRAIN:
  - cityscape_2007_train_t
GLOBAL:
  HACK: 1.0
INPUT:
  AUG_MODE: None
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 600
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - 128
    - 256
    - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: student_sfda_RCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 8
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 300
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./checkpoint/foggy
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 70000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS: []
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
SOURCE_FREE:
  MODE: true
  PETS:
    BETA: 0.5
    CONF_THRESH: 0.6
    EMA_KEEP_RATE: 0.999
    ENABLED: true
    EPOCH_ITERS: 0
    EXCHANGE_PERIOD: 3
    IOU_THRESH: 0.5
    TOTAL_EPOCHS: 10
    WARMUP_EPOCHS: 4
  TYPE: true
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 2000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/24 01:03:17] detectron2 INFO: Full config saved to ./checkpoint/foggy/config.yaml
[02/24 01:03:17] d2.utils.env INFO: Using a generated random seed 17747000
[02/24 01:03:23] detectron2 INFO: Model:
student_sfda_RCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 9, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 36, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=9, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=32, bias=True)
    )
  )
  (GraphCN): GCN(
    (graph): Feat2Graph(
      (wq): Linear(in_features=2048, out_features=2048, bias=True)
      (wk): Linear(in_features=2048, out_features=2048, bias=True)
    )
    (gc1): GraphConvolution (2048 -> 512)
    (gc2): GraphConvolution (512 -> 512)
    (gc3): GraphConvolution (512 -> 2048)
  )
  (Graph_conloss): GraphConLoss(
    (head_1): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
    (head_2): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
)
[02/24 01:03:23] detectron2 INFO: Models built. Starting training...
[02/24 01:03:25] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 01:03:25] d2.data.build INFO: Distribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 17994        |   rider    | 1807         |    car     | 27155        |
|   truck    | 489          |    bus     | 385          |   train    | 171          |
| motorcycle | 739          |  bicycle   | 3729         |            |              |
|   total    | 52469        |            |              |            |              |[0m
[02/24 01:03:25] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbc051c2be0>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 01:03:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 01:03:25] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 01:03:25] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 01:03:25] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 01:03:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/24 01:03:25] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mGraphCN.gc1.{bias, weight}[0m
[34mGraphCN.gc2.{bias, weight}[0m
[34mGraphCN.gc3.{bias, weight}[0m
[34mGraphCN.graph.wk.{bias, weight}[0m
[34mGraphCN.graph.wq.{bias, weight}[0m
[34mGraph_conloss.head_1.0.{bias, weight}[0m
[34mGraph_conloss.head_1.2.{bias, weight}[0m
[34mGraph_conloss.head_2.0.{bias, weight}[0m
[34mGraph_conloss.head_2.2.{bias, weight}[0m
[02/24 01:03:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/24 01:03:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/24 01:03:25] detectron2 INFO: Starting training from iteration 0
[02/24 01:03:26] d2.data.build INFO: Distribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 3419         |   rider    | 556          |    car     | 4667         |
|   truck    | 93           |    bus     | 98           |   train    | 23           |
| motorcycle | 149          |  bicycle   | 1175         |            |              |
|   total    | 10180        |            |              |            |              |[0m
[02/24 01:03:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 01:03:26] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 01:03:26] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 01:03:26] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 01:04:03] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 01:04:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 01:04:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 01:04:03] d2.evaluation.testing INFO: copypaste: 16.1020,26.5147,16.9521
[02/24 01:04:03] detectron2 INFO: AP for person: 31.691556807863165
[02/24 01:04:03] detectron2 INFO: AP for rider: 39.16751890419787
[02/24 01:04:03] detectron2 INFO: AP for car: 36.086357171952166
[02/24 01:04:03] detectron2 INFO: AP for truck: 18.504190844616378
[02/24 01:04:03] detectron2 INFO: AP for bus: 25.324675324675326
[02/24 01:04:03] detectron2 INFO: AP for train: 9.090909090909092
[02/24 01:04:03] detectron2 INFO: AP for motorcycle: 21.10299047429387
[02/24 01:04:03] detectron2 INFO: AP for bicycle: 31.14937671330722
[02/24 01:04:05] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 01:04:05] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbe3e7eaef0>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 01:04:05] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 01:04:05] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 01:04:05] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 01:04:05] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 01:38:41] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0002964.pth
[02/24 01:38:42] detectron2 INFO: [EPOCH 1][STUDENT] Evaluation start
[02/24 01:38:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 01:38:42] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 01:38:42] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 01:38:42] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 01:39:27] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 01:39:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 01:39:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 01:39:27] d2.evaluation.testing INFO: copypaste: 17.2406,31.0440,16.2093
[02/24 01:39:27] detectron2 INFO: AP for person: 35.30688118957932
[02/24 01:39:27] detectron2 INFO: AP for rider: 43.831282210604556
[02/24 01:39:27] detectron2 INFO: AP for car: 47.291606907567484
[02/24 01:39:27] detectron2 INFO: AP for truck: 19.99041801413343
[02/24 01:39:27] detectron2 INFO: AP for bus: 29.821122273952465
[02/24 01:39:27] detectron2 INFO: AP for train: 13.744588744588743
[02/24 01:39:27] detectron2 INFO: AP for motorcycle: 22.710980775496907
[02/24 01:39:27] detectron2 INFO: AP for bicycle: 35.65476719283477
[02/24 01:39:27] detectron2 INFO: [EPOCH 1][TEACHER] Evaluation start
[02/24 01:39:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 01:39:28] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 01:39:28] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 01:39:28] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 01:40:10] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 01:40:10] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 01:40:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 01:40:10] d2.evaluation.testing INFO: copypaste: 17.6936,30.5564,16.6734
[02/24 01:40:10] detectron2 INFO: AP for person: 34.8875401816079
[02/24 01:40:10] detectron2 INFO: AP for rider: 43.351546633706306
[02/24 01:40:10] detectron2 INFO: AP for car: 43.791136069153936
[02/24 01:40:10] detectron2 INFO: AP for truck: 19.72149892448772
[02/24 01:40:10] detectron2 INFO: AP for bus: 31.620889748549324
[02/24 01:40:10] detectron2 INFO: AP for train: 9.943181818181818
[02/24 01:40:10] detectron2 INFO: AP for motorcycle: 25.284090909090907
[02/24 01:40:10] detectron2 INFO: AP for bicycle: 35.85101261488853
[02/24 01:40:12] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 01:40:13] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbe9ba9a940>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 01:40:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 01:40:13] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 01:40:13] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 01:40:13] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 02:14:48] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0005929.pth
[02/24 02:14:49] detectron2 INFO: [EPOCH 2][STUDENT] Evaluation start
[02/24 02:14:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 02:14:49] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 02:14:49] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 02:14:49] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 02:15:38] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 02:15:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 02:15:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 02:15:38] d2.evaluation.testing INFO: copypaste: 16.6582,29.2950,16.3160
[02/24 02:15:38] detectron2 INFO: AP for person: 34.67149888571485
[02/24 02:15:38] detectron2 INFO: AP for rider: 44.545232927896365
[02/24 02:15:38] detectron2 INFO: AP for car: 48.042841795329636
[02/24 02:15:38] detectron2 INFO: AP for truck: 18.91178651595318
[02/24 02:15:38] detectron2 INFO: AP for bus: 27.817253169365852
[02/24 02:15:38] detectron2 INFO: AP for train: 4.545454545454546
[02/24 02:15:38] detectron2 INFO: AP for motorcycle: 20.375296087332185
[02/24 02:15:38] detectron2 INFO: AP for bicycle: 35.45043249947632
[02/24 02:15:38] detectron2 INFO: [EPOCH 2][TEACHER] Evaluation start
[02/24 02:15:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 02:15:38] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 02:15:38] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 02:15:38] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 02:16:27] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 02:16:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 02:16:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 02:16:27] d2.evaluation.testing INFO: copypaste: 16.7874,30.5880,16.2976
[02/24 02:16:27] detectron2 INFO: AP for person: 34.80870477050589
[02/24 02:16:27] detectron2 INFO: AP for rider: 43.982336936439424
[02/24 02:16:27] detectron2 INFO: AP for car: 47.91573911129798
[02/24 02:16:27] detectron2 INFO: AP for truck: 18.089344145682173
[02/24 02:16:27] detectron2 INFO: AP for bus: 29.87701953219195
[02/24 02:16:27] detectron2 INFO: AP for train: 12.711530893349076
[02/24 02:16:27] detectron2 INFO: AP for motorcycle: 21.836289005389332
[02/24 02:16:27] detectron2 INFO: AP for bicycle: 35.482929920302915
[02/24 02:16:28] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 02:16:29] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbc051c2ba8>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 02:16:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 02:16:29] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 02:16:29] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 02:16:29] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 02:50:59] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0008894.pth
[02/24 02:51:00] detectron2 INFO: [EPOCH 3][STUDENT] Evaluation start
[02/24 02:51:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 02:51:00] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 02:51:00] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 02:51:00] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 02:51:51] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 02:51:51] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 02:51:51] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 02:51:51] d2.evaluation.testing INFO: copypaste: 17.0127,29.0971,15.7900
[02/24 02:51:51] detectron2 INFO: AP for person: 34.06376610932178
[02/24 02:51:51] detectron2 INFO: AP for rider: 43.83232763795504
[02/24 02:51:51] detectron2 INFO: AP for car: 48.3693856457186
[02/24 02:51:51] detectron2 INFO: AP for truck: 19.738948681130974
[02/24 02:51:51] detectron2 INFO: AP for bus: 26.36280114332381
[02/24 02:51:51] detectron2 INFO: AP for train: 4.545454545454546
[02/24 02:51:51] detectron2 INFO: AP for motorcycle: 20.59987970536304
[02/24 02:51:51] detectron2 INFO: AP for bicycle: 35.26421869510416
[02/24 02:51:51] detectron2 INFO: [EPOCH 3][TEACHER] Evaluation start
[02/24 02:51:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 02:51:52] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 02:51:52] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 02:51:52] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 02:52:41] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 02:52:41] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 02:52:41] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 02:52:41] d2.evaluation.testing INFO: copypaste: 16.5046,29.1773,15.3910
[02/24 02:52:41] detectron2 INFO: AP for person: 34.289577255381566
[02/24 02:52:41] detectron2 INFO: AP for rider: 44.04308239878232
[02/24 02:52:41] detectron2 INFO: AP for car: 48.22024795870319
[02/24 02:52:41] detectron2 INFO: AP for truck: 19.963166633361215
[02/24 02:52:41] detectron2 INFO: AP for bus: 27.705627705627712
[02/24 02:52:41] detectron2 INFO: AP for train: 3.03030303030303
[02/24 02:52:41] detectron2 INFO: AP for motorcycle: 20.59295967190704
[02/24 02:52:41] detectron2 INFO: AP for bicycle: 35.57336861114319
[02/24 02:52:43] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 02:52:43] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbe3e78c128>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 02:52:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 02:52:43] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 02:52:43] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 02:52:43] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 03:27:07] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0011859.pth
[02/24 03:27:09] detectron2 INFO: [EPOCH 4][STUDENT] Evaluation start
[02/24 03:27:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 03:27:09] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 03:27:09] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 03:27:09] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 03:28:01] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 03:28:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 03:28:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 03:28:01] d2.evaluation.testing INFO: copypaste: 16.5816,29.3140,15.5583
[02/24 03:28:01] detectron2 INFO: AP for person: 34.350826213964254
[02/24 03:28:01] detectron2 INFO: AP for rider: 43.7926742965638
[02/24 03:28:01] detectron2 INFO: AP for car: 48.282636049487834
[02/24 03:28:01] detectron2 INFO: AP for truck: 21.059055393819342
[02/24 03:28:01] detectron2 INFO: AP for bus: 26.420454545454547
[02/24 03:28:01] detectron2 INFO: AP for train: 4.545454545454546
[02/24 03:28:01] detectron2 INFO: AP for motorcycle: 20.527810757600804
[02/24 03:28:01] detectron2 INFO: AP for bicycle: 35.53276420319957
[02/24 03:28:01] detectron2 INFO: [EPOCH 4][TEACHER] Evaluation start
[02/24 03:28:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 03:28:01] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 03:28:01] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 03:28:01] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 03:28:52] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 03:28:52] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 03:28:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 03:28:52] d2.evaluation.testing INFO: copypaste: 16.3334,29.2128,15.3396
[02/24 03:28:52] detectron2 INFO: AP for person: 34.546886107369914
[02/24 03:28:52] detectron2 INFO: AP for rider: 43.619140480116094
[02/24 03:28:52] detectron2 INFO: AP for car: 48.29863206814344
[02/24 03:28:52] detectron2 INFO: AP for truck: 20.44536454513664
[02/24 03:28:52] detectron2 INFO: AP for bus: 26.248944553898117
[02/24 03:28:52] detectron2 INFO: AP for train: 4.545454545454546
[02/24 03:28:52] detectron2 INFO: AP for motorcycle: 20.984770625058395
[02/24 03:28:52] detectron2 INFO: AP for bicycle: 35.013380092770426
[02/24 03:28:54] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 03:28:54] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbe13fdfda0>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 03:28:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 03:28:54] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 03:28:54] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 03:28:54] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 04:03:20] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0014824.pth
[02/24 04:03:21] detectron2 INFO: [EPOCH 5][STUDENT] Evaluation start
[02/24 04:03:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 04:03:21] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 04:03:21] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 04:03:21] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 04:04:14] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 04:04:14] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 04:04:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 04:04:14] d2.evaluation.testing INFO: copypaste: 16.6169,29.4105,15.8388
[02/24 04:04:14] detectron2 INFO: AP for person: 34.32210263947761
[02/24 04:04:14] detectron2 INFO: AP for rider: 43.81034952141899
[02/24 04:04:14] detectron2 INFO: AP for car: 48.302258165645455
[02/24 04:04:14] detectron2 INFO: AP for truck: 20.972421050635674
[02/24 04:04:14] detectron2 INFO: AP for bus: 26.891676714497414
[02/24 04:04:14] detectron2 INFO: AP for train: 4.545454545454546
[02/24 04:04:14] detectron2 INFO: AP for motorcycle: 20.72301163210254
[02/24 04:04:14] detectron2 INFO: AP for bicycle: 35.71701177504123
[02/24 04:04:14] detectron2 INFO: [EPOCH 5][TEACHER] Evaluation start
[02/24 04:04:15] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 04:04:15] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 04:04:15] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 04:04:15] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 04:05:06] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 04:05:06] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 04:05:06] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 04:05:06] d2.evaluation.testing INFO: copypaste: 16.6816,29.2237,15.4031
[02/24 04:05:06] detectron2 INFO: AP for person: 34.29394335267214
[02/24 04:05:06] detectron2 INFO: AP for rider: 43.76557063847895
[02/24 04:05:06] detectron2 INFO: AP for car: 48.38657814339916
[02/24 04:05:06] detectron2 INFO: AP for truck: 21.23847167325428
[02/24 04:05:06] detectron2 INFO: AP for bus: 26.882761561284134
[02/24 04:05:06] detectron2 INFO: AP for train: 4.545454545454546
[02/24 04:05:06] detectron2 INFO: AP for motorcycle: 18.875908759070718
[02/24 04:05:06] detectron2 INFO: AP for bicycle: 35.80077727071891
[02/24 04:05:08] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 04:05:08] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbe3e7d45f8>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 04:05:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 04:05:08] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 04:05:08] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 04:05:09] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 04:39:35] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0017789.pth
[02/24 04:39:36] detectron2 INFO: [EPOCH 6][STUDENT] Evaluation start
[02/24 04:39:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 04:39:36] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 04:39:36] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 04:39:36] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 04:40:16] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 04:40:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 04:40:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 04:40:16] d2.evaluation.testing INFO: copypaste: 16.1020,26.5147,16.9521
[02/24 04:40:16] detectron2 INFO: AP for person: 31.691556807863165
[02/24 04:40:16] detectron2 INFO: AP for rider: 39.16751890419787
[02/24 04:40:16] detectron2 INFO: AP for car: 36.086357171952166
[02/24 04:40:16] detectron2 INFO: AP for truck: 18.504190844616378
[02/24 04:40:16] detectron2 INFO: AP for bus: 25.324675324675326
[02/24 04:40:16] detectron2 INFO: AP for train: 9.090909090909092
[02/24 04:40:16] detectron2 INFO: AP for motorcycle: 21.10299047429387
[02/24 04:40:16] detectron2 INFO: AP for bicycle: 31.14937671330722
[02/24 04:40:16] detectron2 INFO: [EPOCH 6][TEACHER] Evaluation start
[02/24 04:40:16] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 04:40:16] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 04:40:16] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 04:40:16] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 04:41:09] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 04:41:09] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 04:41:09] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 04:41:09] d2.evaluation.testing INFO: copypaste: 16.8523,29.3483,16.5874
[02/24 04:41:09] detectron2 INFO: AP for person: 34.46465501743715
[02/24 04:41:09] detectron2 INFO: AP for rider: 43.983731174562905
[02/24 04:41:09] detectron2 INFO: AP for car: 48.2799067095762
[02/24 04:41:09] detectron2 INFO: AP for truck: 21.00230136295331
[02/24 04:41:09] detectron2 INFO: AP for bus: 25.878178335074885
[02/24 04:41:09] detectron2 INFO: AP for train: 4.545454545454546
[02/24 04:41:09] detectron2 INFO: AP for motorcycle: 20.79955276475311
[02/24 04:41:09] detectron2 INFO: AP for bicycle: 35.83290338959775
[02/24 04:41:10] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 04:41:11] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbe3e7d4240>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 04:41:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 04:41:11] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 04:41:11] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 04:41:11] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 05:15:59] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0020754.pth
[02/24 05:16:00] detectron2 INFO: [EPOCH 7][STUDENT] Evaluation start
[02/24 05:16:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 05:16:00] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 05:16:00] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 05:16:00] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 05:16:50] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 05:16:50] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 05:16:50] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 05:16:50] d2.evaluation.testing INFO: copypaste: 16.4176,28.8663,16.2323
[02/24 05:16:50] detectron2 INFO: AP for person: 33.988712534106
[02/24 05:16:50] detectron2 INFO: AP for rider: 43.89059709999416
[02/24 05:16:50] detectron2 INFO: AP for car: 47.880291348556995
[02/24 05:16:50] detectron2 INFO: AP for truck: 19.886989923732116
[02/24 05:16:50] detectron2 INFO: AP for bus: 27.714987714987714
[02/24 05:16:50] detectron2 INFO: AP for train: 3.03030303030303
[02/24 05:16:50] detectron2 INFO: AP for motorcycle: 19.798399275143463
[02/24 05:16:50] detectron2 INFO: AP for bicycle: 34.74022950062221
[02/24 05:16:50] detectron2 INFO: [EPOCH 7][TEACHER] Evaluation start
[02/24 05:16:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 05:16:50] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 05:16:50] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 05:16:50] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 05:17:38] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 05:17:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 05:17:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 05:17:38] d2.evaluation.testing INFO: copypaste: 16.7597,29.2111,15.7298
[02/24 05:17:38] detectron2 INFO: AP for person: 34.5823038060181
[02/24 05:17:38] detectron2 INFO: AP for rider: 44.234037742048436
[02/24 05:17:38] detectron2 INFO: AP for car: 47.871217621570686
[02/24 05:17:38] detectron2 INFO: AP for truck: 18.478733162748032
[02/24 05:17:38] detectron2 INFO: AP for bus: 27.123400830297385
[02/24 05:17:38] detectron2 INFO: AP for train: 4.545454545454546
[02/24 05:17:38] detectron2 INFO: AP for motorcycle: 21.5937764203931
[02/24 05:17:38] detectron2 INFO: AP for bicycle: 35.26008059997125
[02/24 05:17:40] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 05:17:40] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbe3e7be438>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 05:17:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 05:17:40] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 05:17:40] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 05:17:40] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 05:52:31] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0023719.pth
[02/24 05:52:31] detectron2 INFO: [EPOCH 8][STUDENT] Evaluation start
[02/24 05:52:32] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 05:52:32] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 05:52:32] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 05:52:32] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 05:53:25] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 05:53:25] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 05:53:25] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 05:53:25] d2.evaluation.testing INFO: copypaste: 16.0522,28.0833,15.3875
[02/24 05:53:25] detectron2 INFO: AP for person: 33.19040885173523
[02/24 05:53:25] detectron2 INFO: AP for rider: 43.74563965916921
[02/24 05:53:25] detectron2 INFO: AP for car: 47.94026798753301
[02/24 05:53:25] detectron2 INFO: AP for truck: 19.731950990960527
[02/24 05:53:25] detectron2 INFO: AP for bus: 23.145379838293227
[02/24 05:53:25] detectron2 INFO: AP for train: 4.545454545454546
[02/24 05:53:25] detectron2 INFO: AP for motorcycle: 18.051166794318583
[02/24 05:53:25] detectron2 INFO: AP for bicycle: 34.31642761320251
[02/24 05:53:25] detectron2 INFO: [EPOCH 8][TEACHER] Evaluation start
[02/24 05:53:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 05:53:25] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 05:53:25] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 05:53:25] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 05:54:17] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 05:54:17] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 05:54:17] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 05:54:17] d2.evaluation.testing INFO: copypaste: 16.6495,28.5707,16.0614
[02/24 05:54:17] detectron2 INFO: AP for person: 33.49443470543076
[02/24 05:54:17] detectron2 INFO: AP for rider: 43.68958265511504
[02/24 05:54:17] detectron2 INFO: AP for car: 47.903434659927406
[02/24 05:54:17] detectron2 INFO: AP for truck: 21.288213854913813
[02/24 05:54:17] detectron2 INFO: AP for bus: 24.43877551020408
[02/24 05:54:17] detectron2 INFO: AP for train: 4.545454545454546
[02/24 05:54:17] detectron2 INFO: AP for motorcycle: 18.900664552838467
[02/24 05:54:17] detectron2 INFO: AP for bicycle: 34.30513979164201
[02/24 05:54:19] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 05:54:19] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbecef7d128>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 05:54:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 05:54:19] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 05:54:19] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 05:54:20] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 06:29:04] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0026684.pth
[02/24 06:29:05] detectron2 INFO: [EPOCH 9][STUDENT] Evaluation start
[02/24 06:29:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 06:29:06] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 06:29:06] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 06:29:06] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 06:29:59] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 06:29:59] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 06:29:59] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 06:29:59] d2.evaluation.testing INFO: copypaste: 16.5399,29.2387,16.1415
[02/24 06:29:59] detectron2 INFO: AP for person: 34.30881431024721
[02/24 06:29:59] detectron2 INFO: AP for rider: 44.31537548320911
[02/24 06:29:59] detectron2 INFO: AP for car: 48.428443189195
[02/24 06:29:59] detectron2 INFO: AP for truck: 21.04436152213193
[02/24 06:29:59] detectron2 INFO: AP for bus: 27.445281990736536
[02/24 06:29:59] detectron2 INFO: AP for train: 4.545454545454546
[02/24 06:29:59] detectron2 INFO: AP for motorcycle: 18.243763015852778
[02/24 06:29:59] detectron2 INFO: AP for bicycle: 35.57778788621737
[02/24 06:29:59] detectron2 INFO: [EPOCH 9][TEACHER] Evaluation start
[02/24 06:29:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 06:29:59] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 06:30:00] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 06:30:00] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 06:30:54] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 06:30:54] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 06:30:54] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 06:30:54] d2.evaluation.testing INFO: copypaste: 15.5728,28.0682,15.2757
[02/24 06:30:54] detectron2 INFO: AP for person: 32.90490984843126
[02/24 06:30:54] detectron2 INFO: AP for rider: 43.59029999828307
[02/24 06:30:54] detectron2 INFO: AP for car: 47.753556896207286
[02/24 06:30:54] detectron2 INFO: AP for truck: 19.353911205074
[02/24 06:30:54] detectron2 INFO: AP for bus: 24.91374172046441
[02/24 06:30:54] detectron2 INFO: AP for train: 4.545454545454546
[02/24 06:30:54] detectron2 INFO: AP for motorcycle: 17.305263446912495
[02/24 06:30:54] detectron2 INFO: AP for bicycle: 34.1781059194869
[02/24 06:30:56] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/24 06:30:56] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fbebd9ac9b0>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/24 06:30:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 06:30:56] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 06:30:56] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/24 06:30:56] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/24 07:05:56] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0029649.pth
[02/24 07:05:56] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_final.pth
[02/24 07:05:57] detectron2 INFO: [EPOCH 10][STUDENT] Evaluation start
[02/24 07:05:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 07:05:58] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 07:05:58] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 07:05:58] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 07:06:53] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 07:06:53] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 07:06:53] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 07:06:53] d2.evaluation.testing INFO: copypaste: 15.4190,27.3997,14.4916
[02/24 07:06:53] detectron2 INFO: AP for person: 33.146392479626925
[02/24 07:06:53] detectron2 INFO: AP for rider: 43.76389848551007
[02/24 07:06:53] detectron2 INFO: AP for car: 47.86777676049343
[02/24 07:06:53] detectron2 INFO: AP for truck: 18.397490360107184
[02/24 07:06:53] detectron2 INFO: AP for bus: 23.177930716733375
[02/24 07:06:53] detectron2 INFO: AP for train: 1.8181818181818183
[02/24 07:06:53] detectron2 INFO: AP for motorcycle: 16.8528604012475
[02/24 07:06:53] detectron2 INFO: AP for bicycle: 34.173463446824165
[02/24 07:06:53] detectron2 INFO: [EPOCH 10][TEACHER] Evaluation start
[02/24 07:06:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 07:06:54] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 07:06:54] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 07:06:54] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 07:07:48] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 07:07:48] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 07:07:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 07:07:48] d2.evaluation.testing INFO: copypaste: 15.3780,27.6867,14.8137
[02/24 07:07:48] detectron2 INFO: AP for person: 33.13220630148685
[02/24 07:07:48] detectron2 INFO: AP for rider: 43.75882560012088
[02/24 07:07:48] detectron2 INFO: AP for car: 48.07762048637428
[02/24 07:07:48] detectron2 INFO: AP for truck: 19.408006262558885
[02/24 07:07:48] detectron2 INFO: AP for bus: 23.744183114244073
[02/24 07:07:48] detectron2 INFO: AP for train: 2.272727272727273
[02/24 07:07:48] detectron2 INFO: AP for motorcycle: 16.959907334238885
[02/24 07:07:48] detectron2 INFO: AP for bicycle: 34.13982619825952
[02/24 07:07:48] detectron2 INFO: [FINAL][STUDENT] Evaluation start
[02/24 07:07:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 07:07:49] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 07:07:49] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 07:07:49] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 07:08:43] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 07:08:43] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 07:08:43] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 07:08:43] d2.evaluation.testing INFO: copypaste: 15.4190,27.3997,14.4916
[02/24 07:08:43] detectron2 INFO: AP for person: 33.146392479626925
[02/24 07:08:43] detectron2 INFO: AP for rider: 43.76389848551007
[02/24 07:08:43] detectron2 INFO: AP for car: 47.86777676049343
[02/24 07:08:43] detectron2 INFO: AP for truck: 18.397490360107184
[02/24 07:08:43] detectron2 INFO: AP for bus: 23.177930716733375
[02/24 07:08:43] detectron2 INFO: AP for train: 1.8181818181818183
[02/24 07:08:43] detectron2 INFO: AP for motorcycle: 16.8528604012475
[02/24 07:08:43] detectron2 INFO: AP for bicycle: 34.173463446824165
[02/24 07:08:43] detectron2 INFO: [FINAL][TEACHER] Evaluation start
[02/24 07:08:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/24 07:08:43] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/24 07:08:43] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/24 07:08:43] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/24 07:09:40] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/24 07:09:40] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/24 07:09:40] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/24 07:09:40] d2.evaluation.testing INFO: copypaste: 15.3780,27.6867,14.8137
[02/24 07:09:40] detectron2 INFO: AP for person: 33.13220630148685
[02/24 07:09:40] detectron2 INFO: AP for rider: 43.75882560012088
[02/24 07:09:40] detectron2 INFO: AP for car: 48.07762048637428
[02/24 07:09:40] detectron2 INFO: AP for truck: 19.408006262558885
[02/24 07:09:40] detectron2 INFO: AP for bus: 23.744183114244073
[02/24 07:09:40] detectron2 INFO: AP for train: 2.272727272727273
[02/24 07:09:40] detectron2 INFO: AP for motorcycle: 16.959907334238885
[02/24 07:09:40] detectron2 INFO: AP for bicycle: 34.13982619825952
