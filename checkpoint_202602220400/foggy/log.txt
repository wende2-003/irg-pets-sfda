[02/22 01:11:58] detectron2 INFO: Rank of current process: 0. World size: 1
[02/22 01:11:59] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:51:32) [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
numpy                   1.19.5
detectron2              0.6 @/root/irg-sfda/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu102 @/root/miniconda3/envs/irg_sfda/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
Driver version          550.90.07
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.0+cu102 @/root/miniconda3/envs/irg_sfda/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.3
----------------------  ---------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/22 01:11:59] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sfda/sfda_foggy.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, model_dir='/root/autodl-tmp/model_final.pth', num_gpus=1, num_machines=1, opts=[], resume=False)
[02/22 01:11:59] detectron2 INFO: Contents of args.config_file=configs/sfda/sfda_foggy.yaml:
MODEL:
  META_ARCHITECTURE: "student_sfda_RCNN"
  WEIGHT: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: False
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 300
    ANCHOR_SIZES: (128, 256, 512)
  ROI_HEADS:
    NUM_CLASSES: 8
  RESNETS:
    NORM: "FrozenBN" 
    OUT_FEATURES: ["res4"]
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MIN_SIZE_TEST: 600
DATASETS:
  TRAIN: ("cityscape_2007_train_t",)
  TEST: ("cityscape_2007_test_t",)
SOLVER:
  BASE_LR: 0.001
  WEIGHT_DECAY: 0.0001
  STEPS: ()
  MAX_ITER: 70000
  IMS_PER_BATCH: 1
  WARMUP_ITERS: 0
  CHECKPOINT_PERIOD: 5000
TEST:
  EVAL_PERIOD: 2000
SOURCE_FREE:
  TYPE: True
  MODE: True
  PETS:
    ENABLED: True
    EXCHANGE_PERIOD: 2
    EMA_KEEP_RATE: 0.999
    CONF_THRESH: 0.5
    IOU_THRESH: 0.5
    BETA: 0.5
    EPOCH_ITERS: 0
    WARMUP_EPOCHS: 2
OUTPUT_DIR: "./checkpoint/foggy"

[02/22 01:11:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - cityscape_2007_test_t
  TRAIN:
  - cityscape_2007_train_t
GLOBAL:
  HACK: 1.0
INPUT:
  AUG_MODE: None
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 600
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - 128
    - 256
    - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: student_sfda_RCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 8
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 300
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./checkpoint/foggy
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 70000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS: []
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
SOURCE_FREE:
  MODE: true
  PETS:
    BETA: 0.5
    CONF_THRESH: 0.5
    EMA_KEEP_RATE: 0.999
    ENABLED: true
    EPOCH_ITERS: 0
    EXCHANGE_PERIOD: 2
    IOU_THRESH: 0.5
    WARMUP_EPOCHS: 2
  TYPE: true
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 2000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/22 01:11:59] detectron2 INFO: Full config saved to ./checkpoint/foggy/config.yaml
[02/22 01:12:00] d2.utils.env INFO: Using a generated random seed 146556
[02/22 01:12:06] detectron2 INFO: Model:
student_sfda_RCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 9, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 36, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=9, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=32, bias=True)
    )
  )
  (GraphCN): GCN(
    (graph): Feat2Graph(
      (wq): Linear(in_features=2048, out_features=2048, bias=True)
      (wk): Linear(in_features=2048, out_features=2048, bias=True)
    )
    (gc1): GraphConvolution (2048 -> 512)
    (gc2): GraphConvolution (512 -> 512)
    (gc3): GraphConvolution (512 -> 2048)
  )
  (Graph_conloss): GraphConLoss(
    (head_1): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
    (head_2): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
)
[02/22 01:12:06] detectron2 INFO: Models built. Starting training...
[02/22 01:12:07] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/22 01:12:07] d2.data.build INFO: Distribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 17994        |   rider    | 1807         |    car     | 27155        |
|   truck    | 489          |    bus     | 385          |   train    | 171          |
| motorcycle | 739          |  bicycle   | 3729         |            |              |
|   total    | 52469        |            |              |            |              |[0m
[02/22 01:12:07] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fa3281a5c50>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/22 01:12:07] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 01:12:07] d2.data.build INFO: Using training sampler TrainingSampler
[02/22 01:12:07] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/22 01:12:07] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/22 01:12:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/22 01:12:08] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mGraphCN.gc1.{bias, weight}[0m
[34mGraphCN.gc2.{bias, weight}[0m
[34mGraphCN.gc3.{bias, weight}[0m
[34mGraphCN.graph.wk.{bias, weight}[0m
[34mGraphCN.graph.wq.{bias, weight}[0m
[34mGraph_conloss.head_1.0.{bias, weight}[0m
[34mGraph_conloss.head_1.2.{bias, weight}[0m
[34mGraph_conloss.head_2.0.{bias, weight}[0m
[34mGraph_conloss.head_2.2.{bias, weight}[0m
[02/22 01:12:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/22 01:12:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/22 01:12:08] detectron2 INFO: Starting training from iteration 0
[02/22 01:12:08] d2.data.build INFO: Distribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 3419         |   rider    | 556          |    car     | 4667         |
|   truck    | 93           |    bus     | 98           |   train    | 23           |
| motorcycle | 149          |  bicycle   | 1175         |            |              |
|   total    | 10180        |            |              |            |              |[0m
[02/22 01:12:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 01:12:08] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 01:12:08] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 01:12:08] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 01:12:47] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 01:12:47] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 01:12:47] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 01:12:47] d2.evaluation.testing INFO: copypaste: 16.1020,26.5147,16.9521
[02/22 01:12:47] detectron2 INFO: AP for person: 31.691556807863165
[02/22 01:12:47] detectron2 INFO: AP for rider: 39.16751890419787
[02/22 01:12:47] detectron2 INFO: AP for car: 36.086357171952166
[02/22 01:12:47] detectron2 INFO: AP for truck: 18.504190844616378
[02/22 01:12:47] detectron2 INFO: AP for bus: 25.324675324675326
[02/22 01:12:47] detectron2 INFO: AP for train: 9.090909090909092
[02/22 01:12:47] detectron2 INFO: AP for motorcycle: 21.10299047429387
[02/22 01:12:47] detectron2 INFO: AP for bicycle: 31.14937671330722
[02/22 01:12:49] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/22 01:12:49] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fa55758aef0>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/22 01:12:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 01:12:49] d2.data.build INFO: Using training sampler TrainingSampler
[02/22 01:12:49] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/22 01:12:49] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/22 01:47:13] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0002964.pth
[02/22 01:47:14] detectron2 INFO: [EPOCH 1][STUDENT] Evaluation start
[02/22 01:47:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 01:47:14] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 01:47:14] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 01:47:14] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 01:47:56] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 01:47:56] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 01:47:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 01:47:56] d2.evaluation.testing INFO: copypaste: 18.1476,33.0928,17.7463
[02/22 01:47:56] detectron2 INFO: AP for person: 32.997189870566864
[02/22 01:47:56] detectron2 INFO: AP for rider: 40.90668403673191
[02/22 01:47:56] detectron2 INFO: AP for car: 50.9891063359954
[02/22 01:47:56] detectron2 INFO: AP for truck: 26.175718221172765
[02/22 01:47:56] detectron2 INFO: AP for bus: 33.7036702053491
[02/22 01:47:56] detectron2 INFO: AP for train: 19.58041958041958
[02/22 01:47:56] detectron2 INFO: AP for motorcycle: 24.610943842566936
[02/22 01:47:56] detectron2 INFO: AP for bicycle: 35.77862482393665
[02/22 01:47:57] detectron2 INFO: [EPOCH 1][TEACHER] Evaluation start
[02/22 01:47:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 01:47:57] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 01:47:57] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 01:47:57] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 01:48:42] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 01:48:42] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 01:48:42] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 01:48:42] d2.evaluation.testing INFO: copypaste: 21.2188,36.4139,19.8650
[02/22 01:48:42] detectron2 INFO: AP for person: 36.86116298805119
[02/22 01:48:42] detectron2 INFO: AP for rider: 45.442694937347454
[02/22 01:48:42] detectron2 INFO: AP for car: 52.027325321809094
[02/22 01:48:42] detectron2 INFO: AP for truck: 24.57313412926032
[02/22 01:48:42] detectron2 INFO: AP for bus: 37.121212121212125
[02/22 01:48:42] detectron2 INFO: AP for train: 30.047846889952158
[02/22 01:48:42] detectron2 INFO: AP for motorcycle: 26.762595776680282
[02/22 01:48:42] detectron2 INFO: AP for bicycle: 38.47506329621326
[02/22 01:48:43] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/22 01:48:44] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fa5464a34a8>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/22 01:48:44] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 01:48:44] d2.data.build INFO: Using training sampler TrainingSampler
[02/22 01:48:44] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/22 01:48:44] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/22 02:23:10] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0005929.pth
[02/22 02:23:11] detectron2 INFO: [EPOCH 2][STUDENT] Evaluation start
[02/22 02:23:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 02:23:11] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 02:23:11] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 02:23:11] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 02:23:54] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 02:23:54] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 02:23:54] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 02:23:54] d2.evaluation.testing INFO: copypaste: 18.6160,33.8125,17.9738
[02/22 02:23:54] detectron2 INFO: AP for person: 37.021601883414384
[02/22 02:23:54] detectron2 INFO: AP for rider: 41.930102433094895
[02/22 02:23:54] detectron2 INFO: AP for car: 52.235503222940515
[02/22 02:23:54] detectron2 INFO: AP for truck: 18.86209029066172
[02/22 02:23:54] detectron2 INFO: AP for bus: 36.45302066354699
[02/22 02:23:54] detectron2 INFO: AP for train: 26.47058823529412
[02/22 02:23:54] detectron2 INFO: AP for motorcycle: 21.722617005635875
[02/22 02:23:54] detectron2 INFO: AP for bicycle: 35.80429489379361
[02/22 02:23:54] detectron2 INFO: [EPOCH 2][TEACHER] Evaluation start
[02/22 02:23:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 02:23:54] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 02:23:54] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 02:23:54] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 02:24:38] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 02:24:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 02:24:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 02:24:38] d2.evaluation.testing INFO: copypaste: 20.8435,37.3902,19.1887
[02/22 02:24:38] detectron2 INFO: AP for person: 37.34268842480999
[02/22 02:24:38] detectron2 INFO: AP for rider: 45.28355519705396
[02/22 02:24:38] detectron2 INFO: AP for car: 51.75371604639369
[02/22 02:24:38] detectron2 INFO: AP for truck: 25.31054482845578
[02/22 02:24:38] detectron2 INFO: AP for bus: 38.865546218487395
[02/22 02:24:38] detectron2 INFO: AP for train: 31.818181818181817
[02/22 02:24:38] detectron2 INFO: AP for motorcycle: 29.55756602947614
[02/22 02:24:38] detectron2 INFO: AP for bicycle: 39.189965564794434
[02/22 02:24:40] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/22 02:24:40] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fa557818ac8>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/22 02:24:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 02:24:40] d2.data.build INFO: Using training sampler TrainingSampler
[02/22 02:24:40] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/22 02:24:40] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/22 02:59:00] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0008894.pth
[02/22 02:59:01] detectron2 INFO: [EPOCH 3][STUDENT] Evaluation start
[02/22 02:59:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 02:59:01] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 02:59:01] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 02:59:01] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 02:59:42] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 02:59:42] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 02:59:42] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 02:59:42] d2.evaluation.testing INFO: copypaste: 17.1813,31.0075,16.4495
[02/22 02:59:42] detectron2 INFO: AP for person: 33.2417742474868
[02/22 02:59:42] detectron2 INFO: AP for rider: 41.69314394701143
[02/22 02:59:42] detectron2 INFO: AP for car: 48.73449429802277
[02/22 02:59:42] detectron2 INFO: AP for truck: 15.328709303186633
[02/22 02:59:42] detectron2 INFO: AP for bus: 30.023103123365786
[02/22 02:59:42] detectron2 INFO: AP for train: 20.261360261360263
[02/22 02:59:42] detectron2 INFO: AP for motorcycle: 22.72727272727273
[02/22 02:59:42] detectron2 INFO: AP for bicycle: 36.05044066599339
[02/22 02:59:42] detectron2 INFO: [EPOCH 3][TEACHER] Evaluation start
[02/22 02:59:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 02:59:42] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 02:59:42] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 02:59:42] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 03:00:25] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 03:00:25] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 03:00:25] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 03:00:25] d2.evaluation.testing INFO: copypaste: 20.5792,36.5806,19.4205
[02/22 03:00:25] detectron2 INFO: AP for person: 37.666568993902786
[02/22 03:00:25] detectron2 INFO: AP for rider: 45.69758145308464
[02/22 03:00:25] detectron2 INFO: AP for car: 51.82937051466282
[02/22 03:00:25] detectron2 INFO: AP for truck: 22.092547092547093
[02/22 03:00:25] detectron2 INFO: AP for bus: 37.10635769459299
[02/22 03:00:25] detectron2 INFO: AP for train: 31.818181818181817
[02/22 03:00:25] detectron2 INFO: AP for motorcycle: 28.257510392972
[02/22 03:00:25] detectron2 INFO: AP for bicycle: 38.17681143435989
[02/22 03:00:27] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/22 03:00:27] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fa53529b240>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/22 03:00:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 03:00:27] d2.data.build INFO: Using training sampler TrainingSampler
[02/22 03:00:27] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/22 03:00:27] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/22 03:34:49] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0011859.pth
[02/22 03:34:50] detectron2 INFO: [EPOCH 4][STUDENT] Evaluation start
[02/22 03:34:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 03:34:50] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 03:34:50] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 03:34:50] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 03:35:29] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 03:35:29] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 03:35:29] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 03:35:29] d2.evaluation.testing INFO: copypaste: 16.1020,26.5147,16.9521
[02/22 03:35:29] detectron2 INFO: AP for person: 31.691556807863165
[02/22 03:35:29] detectron2 INFO: AP for rider: 39.16751890419787
[02/22 03:35:29] detectron2 INFO: AP for car: 36.086357171952166
[02/22 03:35:29] detectron2 INFO: AP for truck: 18.504190844616378
[02/22 03:35:29] detectron2 INFO: AP for bus: 25.324675324675326
[02/22 03:35:29] detectron2 INFO: AP for train: 9.090909090909092
[02/22 03:35:29] detectron2 INFO: AP for motorcycle: 21.10299047429387
[02/22 03:35:29] detectron2 INFO: AP for bicycle: 31.14937671330722
[02/22 03:35:29] detectron2 INFO: [EPOCH 4][TEACHER] Evaluation start
[02/22 03:35:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 03:35:30] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 03:35:30] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 03:35:30] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 03:36:12] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 03:36:12] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 03:36:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 03:36:12] d2.evaluation.testing INFO: copypaste: 20.1862,35.4419,20.1195
[02/22 03:36:12] detectron2 INFO: AP for person: 37.29046306963119
[02/22 03:36:12] detectron2 INFO: AP for rider: 42.11006568222246
[02/22 03:36:12] detectron2 INFO: AP for car: 51.797869704366605
[02/22 03:36:12] detectron2 INFO: AP for truck: 22.41758241758242
[02/22 03:36:12] detectron2 INFO: AP for bus: 38.289154454567985
[02/22 03:36:12] detectron2 INFO: AP for train: 22.727272727272723
[02/22 03:36:12] detectron2 INFO: AP for motorcycle: 29.823325049763238
[02/22 03:36:12] detectron2 INFO: AP for bicycle: 39.07971438424387
[02/22 03:36:14] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/22 03:36:14] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fa55759bb00>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/22 03:36:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 03:36:14] d2.data.build INFO: Using training sampler TrainingSampler
[02/22 03:36:14] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/22 03:36:14] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/22 04:10:40] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0014824.pth
[02/22 04:10:40] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_final.pth
[02/22 04:10:41] detectron2 INFO: [EPOCH 5][STUDENT] Evaluation start
[02/22 04:10:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 04:10:42] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 04:10:42] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 04:10:42] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 04:11:27] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 04:11:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 04:11:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 04:11:27] d2.evaluation.testing INFO: copypaste: 16.2375,30.1679,15.9092
[02/22 04:11:27] detectron2 INFO: AP for person: 34.34000705995653
[02/22 04:11:27] detectron2 INFO: AP for rider: 39.21787178324864
[02/22 04:11:27] detectron2 INFO: AP for car: 51.1611477986217
[02/22 04:11:27] detectron2 INFO: AP for truck: 22.43558580456976
[02/22 04:11:27] detectron2 INFO: AP for bus: 33.28222940871162
[02/22 04:11:27] detectron2 INFO: AP for train: 7.7056277056277045
[02/22 04:11:27] detectron2 INFO: AP for motorcycle: 20.56009006473403
[02/22 04:11:27] detectron2 INFO: AP for bicycle: 32.64037223505098
[02/22 04:11:27] detectron2 INFO: [EPOCH 5][TEACHER] Evaluation start
[02/22 04:11:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 04:11:27] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 04:11:27] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 04:11:27] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 04:12:14] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 04:12:14] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 04:12:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 04:12:14] d2.evaluation.testing INFO: copypaste: 18.7359,33.9948,17.8800
[02/22 04:12:14] detectron2 INFO: AP for person: 37.272152595378486
[02/22 04:12:14] detectron2 INFO: AP for rider: 41.54590447849455
[02/22 04:12:14] detectron2 INFO: AP for car: 51.958591815492625
[02/22 04:12:14] detectron2 INFO: AP for truck: 19.23076923076923
[02/22 04:12:14] detectron2 INFO: AP for bus: 33.58798309521832
[02/22 04:12:14] detectron2 INFO: AP for train: 24.9554367201426
[02/22 04:12:14] detectron2 INFO: AP for motorcycle: 24.642171096716552
[02/22 04:12:14] detectron2 INFO: AP for bicycle: 38.765029490532015
[02/22 04:12:15] detectron2 INFO: [FINAL][STUDENT] Evaluation start
[02/22 04:12:15] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 04:12:15] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 04:12:15] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 04:12:15] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 04:13:00] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 04:13:00] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 04:13:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 04:13:00] d2.evaluation.testing INFO: copypaste: 16.2375,30.1679,15.9092
[02/22 04:13:00] detectron2 INFO: AP for person: 34.34000705995653
[02/22 04:13:00] detectron2 INFO: AP for rider: 39.21787178324864
[02/22 04:13:00] detectron2 INFO: AP for car: 51.1611477986217
[02/22 04:13:00] detectron2 INFO: AP for truck: 22.43558580456976
[02/22 04:13:00] detectron2 INFO: AP for bus: 33.28222940871162
[02/22 04:13:00] detectron2 INFO: AP for train: 7.7056277056277045
[02/22 04:13:00] detectron2 INFO: AP for motorcycle: 20.56009006473403
[02/22 04:13:00] detectron2 INFO: AP for bicycle: 32.64037223505098
[02/22 04:13:00] detectron2 INFO: [FINAL][TEACHER] Evaluation start
[02/22 04:13:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/22 04:13:01] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/22 04:13:01] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/22 04:13:01] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/22 04:13:47] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/22 04:13:47] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/22 04:13:47] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/22 04:13:47] d2.evaluation.testing INFO: copypaste: 18.7359,33.9948,17.8800
[02/22 04:13:47] detectron2 INFO: AP for person: 37.272152595378486
[02/22 04:13:47] detectron2 INFO: AP for rider: 41.54590447849455
[02/22 04:13:47] detectron2 INFO: AP for car: 51.958591815492625
[02/22 04:13:47] detectron2 INFO: AP for truck: 19.23076923076923
[02/22 04:13:47] detectron2 INFO: AP for bus: 33.58798309521832
[02/22 04:13:47] detectron2 INFO: AP for train: 24.9554367201426
[02/22 04:13:47] detectron2 INFO: AP for motorcycle: 24.642171096716552
[02/22 04:13:47] detectron2 INFO: AP for bicycle: 38.765029490532015
