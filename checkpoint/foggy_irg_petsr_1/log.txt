[02/27 05:20:30] detectron2 INFO: Rank of current process: 0. World size: 1
[02/27 05:20:31] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:51:32) [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
numpy                   1.19.5
detectron2              0.6 @/root/irg-sfda/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu102 @/root/miniconda3/envs/irg_sfda/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
Driver version          550.90.07
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.0+cu102 @/root/miniconda3/envs/irg_sfda/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.3
----------------------  ---------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/27 05:20:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sfda/sfda_foggy.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, model_dir='/root/autodl-tmp/model_final.pth', num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './checkpoint/foggy_irg_petsr_1'], resume=False)
[02/27 05:20:31] detectron2 INFO: Contents of args.config_file=configs/sfda/sfda_foggy.yaml:
MODEL:
  META_ARCHITECTURE: "student_sfda_RCNN"
  WEIGHT: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: False
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 300
    ANCHOR_SIZES: (128, 256, 512)
  ROI_HEADS:
    NUM_CLASSES: 8
  RESNETS:
    NORM: "FrozenBN" 
    OUT_FEATURES: ["res4"]
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MIN_SIZE_TEST: 600
DATASETS:
  TRAIN: ("cityscape_2007_train_t",)
  TEST: ("cityscape_2007_test_t",)
SOLVER:
  BASE_LR: 0.001
  WEIGHT_DECAY: 0.0001
  STEPS: ()
  MAX_ITER: 70000
  IMS_PER_BATCH: 1
  WARMUP_ITERS: 0
  CHECKPOINT_PERIOD: 5000
TEST:
  EVAL_PERIOD: 2000
SOURCE_FREE:
  TYPE: True
  MODE: True
  PETS:
    ENABLED: True
    EXCHANGE_PERIOD: 1
    EMA_KEEP_RATE: 0.9
    # CONF_THRESH: 0.9
    DT_CONF_THRESH: 0.9
    ST_CONF_THRESH: 0.9
    IOU_THRESH: 0.5
    # BETA: 0.5
    DT_BOX_WEIGHT: 0.95
    DT_SCORE_WEIGHT: 0.95
    EPOCH_ITERS: 0
    TOTAL_EPOCHS: 5
    WARMUP_EPOCHS: 1
OUTPUT_DIR: "./checkpoint/foggy"

[02/27 05:20:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - cityscape_2007_test_t
  TRAIN:
  - cityscape_2007_train_t
GLOBAL:
  HACK: 1.0
INPUT:
  AUG_MODE: None
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 600
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - 128
    - 256
    - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: student_sfda_RCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 8
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 300
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./checkpoint/foggy_irg_petsr_1
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 70000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS: []
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
SOURCE_FREE:
  MODE: true
  PETS:
    BETA: 0.5
    CONF_THRESH: 0.5
    DT_BOX_WEIGHT: 0.95
    DT_CONF_THRESH: 0.9
    DT_SCORE_WEIGHT: 0.95
    EMA_KEEP_RATE: 0.9
    ENABLED: true
    EPOCH_ITERS: 0
    EXCHANGE_PERIOD: 1
    IOU_THRESH: 0.5
    ST_CONF_THRESH: 0.9
    TOTAL_EPOCHS: 5
    WARMUP_EPOCHS: 1
  TYPE: true
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 2000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/27 05:20:32] detectron2 INFO: Full config saved to ./checkpoint/foggy_irg_petsr_1/config.yaml
[02/27 05:20:32] d2.utils.env INFO: Using a generated random seed 32182577
[02/27 05:20:38] detectron2 INFO: Model:
student_sfda_RCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 9, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 36, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=9, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=32, bias=True)
    )
  )
  (GraphCN): GCN(
    (graph): Feat2Graph(
      (wq): Linear(in_features=2048, out_features=2048, bias=True)
      (wk): Linear(in_features=2048, out_features=2048, bias=True)
    )
    (gc1): GraphConvolution (2048 -> 512)
    (gc2): GraphConvolution (512 -> 512)
    (gc3): GraphConvolution (512 -> 2048)
  )
  (Graph_conloss): GraphConLoss(
    (head_1): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
    (head_2): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
)
[02/27 05:20:38] detectron2 INFO: Models built. Starting training...
[02/27 05:20:40] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/27 05:20:40] d2.data.build INFO: Distribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 17994        |   rider    | 1807         |    car     | 27155        |
|   truck    | 489          |    bus     | 385          |   train    | 171          |
| motorcycle | 739          |  bicycle   | 3729         |            |              |
|   total    | 52469        |            |              |            |              |[0m
[02/27 05:20:40] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fb1243b0a58>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/27 05:20:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 05:20:40] d2.data.build INFO: Using training sampler TrainingSampler
[02/27 05:20:40] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/27 05:20:40] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/27 05:20:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/27 05:20:41] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mGraphCN.gc1.{bias, weight}[0m
[34mGraphCN.gc2.{bias, weight}[0m
[34mGraphCN.gc3.{bias, weight}[0m
[34mGraphCN.graph.wk.{bias, weight}[0m
[34mGraphCN.graph.wq.{bias, weight}[0m
[34mGraph_conloss.head_1.0.{bias, weight}[0m
[34mGraph_conloss.head_1.2.{bias, weight}[0m
[34mGraph_conloss.head_2.0.{bias, weight}[0m
[34mGraph_conloss.head_2.2.{bias, weight}[0m
[02/27 05:20:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/27 05:20:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/27 05:20:41] detectron2 INFO: Starting training from iteration 0
[02/27 05:20:41] d2.data.build INFO: Distribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 3419         |   rider    | 556          |    car     | 4667         |
|   truck    | 93           |    bus     | 98           |   train    | 23           |
| motorcycle | 149          |  bicycle   | 1175         |            |              |
|   total    | 10180        |            |              |            |              |[0m
[02/27 05:20:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 05:20:41] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 05:20:41] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 05:20:41] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 05:21:18] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 05:21:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 05:21:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 05:21:18] d2.evaluation.testing INFO: copypaste: 16.1020,26.5147,16.9521
[02/27 05:21:18] detectron2 INFO: AP for person: 31.691556807863165
[02/27 05:21:18] detectron2 INFO: AP for rider: 39.16751890419787
[02/27 05:21:18] detectron2 INFO: AP for car: 36.086357171952166
[02/27 05:21:18] detectron2 INFO: AP for truck: 18.504190844616378
[02/27 05:21:18] detectron2 INFO: AP for bus: 25.324675324675326
[02/27 05:21:18] detectron2 INFO: AP for train: 9.090909090909092
[02/27 05:21:18] detectron2 INFO: AP for motorcycle: 21.10299047429387
[02/27 05:21:18] detectron2 INFO: AP for bicycle: 31.14937671330722
[02/27 05:21:20] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/27 05:21:20] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fb1901e2f98>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/27 05:21:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 05:21:20] d2.data.build INFO: Using training sampler TrainingSampler
[02/27 05:21:20] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/27 05:21:20] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/27 05:53:42] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy_irg_petsr_1/model_0002964.pth
[02/27 05:53:43] detectron2 INFO: [EPOCH 1][STUDENT] Evaluation start
[02/27 05:53:44] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 05:53:44] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 05:53:44] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 05:53:44] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 05:54:20] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 05:54:20] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 05:54:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 05:54:20] d2.evaluation.testing INFO: copypaste: 17.4429,30.6668,16.6727
[02/27 05:54:20] detectron2 INFO: AP for person: 32.24142092269277
[02/27 05:54:20] detectron2 INFO: AP for rider: 33.973698465824455
[02/27 05:54:20] detectron2 INFO: AP for car: 44.19520320235184
[02/27 05:54:20] detectron2 INFO: AP for truck: 22.394678492239468
[02/27 05:54:20] detectron2 INFO: AP for bus: 31.05523318289276
[02/27 05:54:20] detectron2 INFO: AP for train: 27.27272727272727
[02/27 05:54:20] detectron2 INFO: AP for motorcycle: 22.51718869365928
[02/27 05:54:20] detectron2 INFO: AP for bicycle: 31.684595040444023
[02/27 05:54:20] detectron2 INFO: [EPOCH 1][TEACHER] Evaluation start
[02/27 05:54:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 05:54:20] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 05:54:20] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 05:54:20] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 05:54:58] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 05:54:58] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 05:54:58] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 05:54:58] d2.evaluation.testing INFO: copypaste: 17.7315,30.0508,17.2768
[02/27 05:54:58] detectron2 INFO: AP for person: 33.01582116488235
[02/27 05:54:58] detectron2 INFO: AP for rider: 41.05215354117859
[02/27 05:54:58] detectron2 INFO: AP for car: 43.40909021166431
[02/27 05:54:58] detectron2 INFO: AP for truck: 20.05423553719008
[02/27 05:54:58] detectron2 INFO: AP for bus: 31.232754120366916
[02/27 05:54:58] detectron2 INFO: AP for train: 9.090909090909092
[02/27 05:54:58] detectron2 INFO: AP for motorcycle: 26.20965850455014
[02/27 05:54:58] detectron2 INFO: AP for bicycle: 36.341638240952335
[02/27 05:55:00] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/27 05:55:01] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fb190720048>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/27 05:55:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 05:55:01] d2.data.build INFO: Using training sampler TrainingSampler
[02/27 05:55:01] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/27 05:55:01] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/27 06:27:23] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy_irg_petsr_1/model_0005929.pth
[02/27 06:27:24] detectron2 INFO: [EPOCH 2] Refresh static teacher from student (copied 275 shared params)
[02/27 06:27:24] detectron2 INFO: [EPOCH 2][STUDENT] Evaluation start
[02/27 06:27:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 06:27:25] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 06:27:25] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 06:27:25] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 06:28:05] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 06:28:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 06:28:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 06:28:05] d2.evaluation.testing INFO: copypaste: 18.0733,34.2915,17.7057
[02/27 06:28:05] detectron2 INFO: AP for person: 37.4350235819436
[02/27 06:28:05] detectron2 INFO: AP for rider: 45.80689952548702
[02/27 06:28:05] detectron2 INFO: AP for car: 49.44792258514317
[02/27 06:28:05] detectron2 INFO: AP for truck: 21.66469893742621
[02/27 06:28:05] detectron2 INFO: AP for bus: 33.31797706797707
[02/27 06:28:05] detectron2 INFO: AP for train: 23.863636363636363
[02/27 06:28:05] detectron2 INFO: AP for motorcycle: 26.32034632034632
[02/27 06:28:05] detectron2 INFO: AP for bicycle: 36.47537895110864
[02/27 06:28:05] detectron2 INFO: [EPOCH 2][TEACHER] Evaluation start
[02/27 06:28:05] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 06:28:05] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 06:28:05] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 06:28:05] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 06:28:44] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 06:28:44] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 06:28:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 06:28:44] d2.evaluation.testing INFO: copypaste: 18.5725,32.8753,17.4565
[02/27 06:28:44] detectron2 INFO: AP for person: 36.651425141354885
[02/27 06:28:44] detectron2 INFO: AP for rider: 45.626275151242766
[02/27 06:28:44] detectron2 INFO: AP for car: 44.55075135239088
[02/27 06:28:44] detectron2 INFO: AP for truck: 23.262032085561497
[02/27 06:28:44] detectron2 INFO: AP for bus: 33.82663847780126
[02/27 06:28:44] detectron2 INFO: AP for train: 14.102564102564102
[02/27 06:28:44] detectron2 INFO: AP for motorcycle: 26.71356421356421
[02/27 06:28:44] detectron2 INFO: AP for bicycle: 38.26898620057405
[02/27 06:28:46] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/27 06:28:46] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fb190172d30>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/27 06:28:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 06:28:46] d2.data.build INFO: Using training sampler TrainingSampler
[02/27 06:28:46] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/27 06:28:46] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/27 07:01:15] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy_irg_petsr_1/model_0008894.pth
[02/27 07:01:16] detectron2 INFO: [EPOCH 3] Refresh static teacher from student (copied 275 shared params)
[02/27 07:01:16] detectron2 INFO: [EPOCH 3][STUDENT] Evaluation start
[02/27 07:01:16] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 07:01:16] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 07:01:16] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 07:01:16] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 07:01:55] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 07:01:55] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 07:01:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 07:01:55] d2.evaluation.testing INFO: copypaste: 17.8745,32.9782,17.9354
[02/27 07:01:55] detectron2 INFO: AP for person: 36.871618311726564
[02/27 07:01:55] detectron2 INFO: AP for rider: 40.43447194949866
[02/27 07:01:55] detectron2 INFO: AP for car: 49.69711346768448
[02/27 07:01:55] detectron2 INFO: AP for truck: 17.624521072796934
[02/27 07:01:55] detectron2 INFO: AP for bus: 31.719493788459303
[02/27 07:01:55] detectron2 INFO: AP for train: 22.72727272727273
[02/27 07:01:55] detectron2 INFO: AP for motorcycle: 28.197436878743055
[02/27 07:01:55] detectron2 INFO: AP for bicycle: 36.553429812159635
[02/27 07:01:55] detectron2 INFO: [EPOCH 3][TEACHER] Evaluation start
[02/27 07:01:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 07:01:55] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 07:01:55] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 07:01:55] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 07:02:35] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 07:02:35] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 07:02:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 07:02:35] d2.evaluation.testing INFO: copypaste: 19.3055,34.5014,18.2502
[02/27 07:02:35] detectron2 INFO: AP for person: 37.281602584066825
[02/27 07:02:35] detectron2 INFO: AP for rider: 46.09535626429208
[02/27 07:02:35] detectron2 INFO: AP for car: 49.44853193990832
[02/27 07:02:35] detectron2 INFO: AP for truck: 26.059040012528385
[02/27 07:02:35] detectron2 INFO: AP for bus: 33.399209486166
[02/27 07:02:35] detectron2 INFO: AP for train: 16.06060606060606
[02/27 07:02:35] detectron2 INFO: AP for motorcycle: 29.17439703153989
[02/27 07:02:35] detectron2 INFO: AP for bicycle: 38.492288048248405
[02/27 07:02:37] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/27 07:02:37] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fb1524387f0>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/27 07:02:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 07:02:37] d2.data.build INFO: Using training sampler TrainingSampler
[02/27 07:02:37] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/27 07:02:37] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/27 07:35:09] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy_irg_petsr_1/model_0011859.pth
[02/27 07:35:10] detectron2 INFO: [EPOCH 4] Refresh static teacher from student (copied 275 shared params)
[02/27 07:35:10] detectron2 INFO: [EPOCH 4][STUDENT] Evaluation start
[02/27 07:35:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 07:35:11] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 07:35:11] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 07:35:11] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 07:35:52] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 07:35:52] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 07:35:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 07:35:52] d2.evaluation.testing INFO: copypaste: 18.3493,34.3302,17.4197
[02/27 07:35:52] detectron2 INFO: AP for person: 34.256704472107074
[02/27 07:35:52] detectron2 INFO: AP for rider: 45.24324908253944
[02/27 07:35:52] detectron2 INFO: AP for car: 49.7718175935327
[02/27 07:35:52] detectron2 INFO: AP for truck: 25.54702194357367
[02/27 07:35:52] detectron2 INFO: AP for bus: 40.65934065934066
[02/27 07:35:52] detectron2 INFO: AP for train: 18.568245480010184
[02/27 07:35:52] detectron2 INFO: AP for motorcycle: 25.706704969377782
[02/27 07:35:52] detectron2 INFO: AP for bicycle: 34.88814916694784
[02/27 07:35:52] detectron2 INFO: [EPOCH 4][TEACHER] Evaluation start
[02/27 07:35:53] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 07:35:53] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 07:35:53] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 07:35:53] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 07:36:33] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 07:36:33] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 07:36:33] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 07:36:33] d2.evaluation.testing INFO: copypaste: 20.1151,36.0388,20.0654
[02/27 07:36:33] detectron2 INFO: AP for person: 37.556991367951554
[02/27 07:36:33] detectron2 INFO: AP for rider: 46.03652166172134
[02/27 07:36:33] detectron2 INFO: AP for car: 50.41140051062896
[02/27 07:36:33] detectron2 INFO: AP for truck: 23.579545454545457
[02/27 07:36:33] detectron2 INFO: AP for bus: 38.076941665458406
[02/27 07:36:33] detectron2 INFO: AP for train: 24.675324675324678
[02/27 07:36:33] detectron2 INFO: AP for motorcycle: 28.647081074265547
[02/27 07:36:33] detectron2 INFO: AP for bicycle: 39.32690853498279
[02/27 07:36:35] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/27 07:36:35] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7fb1ba83bda0>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/27 07:36:35] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 07:36:35] d2.data.build INFO: Using training sampler TrainingSampler
[02/27 07:36:35] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/27 07:36:35] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/27 08:09:07] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy_irg_petsr_1/model_0014824.pth
[02/27 08:09:08] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy_irg_petsr_1/model_final.pth
[02/27 08:09:09] detectron2 INFO: [EPOCH 5] Refresh static teacher from student (copied 275 shared params)
[02/27 08:09:09] detectron2 INFO: [EPOCH 5][STUDENT] Evaluation start
[02/27 08:09:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 08:09:09] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 08:09:09] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 08:09:09] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 08:09:50] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 08:09:50] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 08:09:50] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 08:09:50] d2.evaluation.testing INFO: copypaste: 19.3015,34.8614,18.4774
[02/27 08:09:50] detectron2 INFO: AP for person: 35.69008720705115
[02/27 08:09:50] detectron2 INFO: AP for rider: 42.15833809365609
[02/27 08:09:50] detectron2 INFO: AP for car: 50.28101653470184
[02/27 08:09:50] detectron2 INFO: AP for truck: 19.840548340548338
[02/27 08:09:50] detectron2 INFO: AP for bus: 38.475345792418956
[02/27 08:09:50] detectron2 INFO: AP for train: 31.100478468899517
[02/27 08:09:50] detectron2 INFO: AP for motorcycle: 24.58058116466332
[02/27 08:09:50] detectron2 INFO: AP for bicycle: 36.764937828056865
[02/27 08:09:50] detectron2 INFO: [EPOCH 5][TEACHER] Evaluation start
[02/27 08:09:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 08:09:50] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 08:09:50] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 08:09:50] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 08:10:30] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 08:10:30] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 08:10:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 08:10:30] d2.evaluation.testing INFO: copypaste: 20.6642,36.7497,19.9215
[02/27 08:10:30] detectron2 INFO: AP for person: 37.67332679432024
[02/27 08:10:30] detectron2 INFO: AP for rider: 45.90749338838164
[02/27 08:10:30] detectron2 INFO: AP for car: 50.65677515188425
[02/27 08:10:30] detectron2 INFO: AP for truck: 25.32948998132751
[02/27 08:10:30] detectron2 INFO: AP for bus: 38.18152283064563
[02/27 08:10:30] detectron2 INFO: AP for train: 26.353965183752422
[02/27 08:10:30] detectron2 INFO: AP for motorcycle: 30.297026908497216
[02/27 08:10:30] detectron2 INFO: AP for bicycle: 39.597622960625706
[02/27 08:10:31] detectron2 INFO: [FINAL][STUDENT] Evaluation start
[02/27 08:10:31] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 08:10:31] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 08:10:31] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 08:10:31] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 08:11:12] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 08:11:12] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 08:11:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 08:11:12] d2.evaluation.testing INFO: copypaste: 19.3015,34.8614,18.4774
[02/27 08:11:12] detectron2 INFO: AP for person: 35.69008720705115
[02/27 08:11:12] detectron2 INFO: AP for rider: 42.15833809365609
[02/27 08:11:12] detectron2 INFO: AP for car: 50.28101653470184
[02/27 08:11:12] detectron2 INFO: AP for truck: 19.840548340548338
[02/27 08:11:12] detectron2 INFO: AP for bus: 38.475345792418956
[02/27 08:11:12] detectron2 INFO: AP for train: 31.100478468899517
[02/27 08:11:12] detectron2 INFO: AP for motorcycle: 24.58058116466332
[02/27 08:11:12] detectron2 INFO: AP for bicycle: 36.764937828056865
[02/27 08:11:12] detectron2 INFO: [FINAL][TEACHER] Evaluation start
[02/27 08:11:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/27 08:11:12] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/27 08:11:12] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/27 08:11:12] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/27 08:11:52] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/27 08:11:52] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/27 08:11:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/27 08:11:52] d2.evaluation.testing INFO: copypaste: 20.6642,36.7497,19.9215
[02/27 08:11:52] detectron2 INFO: AP for person: 37.67332679432024
[02/27 08:11:52] detectron2 INFO: AP for rider: 45.90749338838164
[02/27 08:11:52] detectron2 INFO: AP for car: 50.65677515188425
[02/27 08:11:52] detectron2 INFO: AP for truck: 25.32948998132751
[02/27 08:11:52] detectron2 INFO: AP for bus: 38.18152283064563
[02/27 08:11:52] detectron2 INFO: AP for train: 26.353965183752422
[02/27 08:11:52] detectron2 INFO: AP for motorcycle: 30.297026908497216
[02/27 08:11:52] detectron2 INFO: AP for bicycle: 39.597622960625706
