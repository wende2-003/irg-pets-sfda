[02/25 01:54:04] detectron2 INFO: Rank of current process: 0. World size: 1
[02/25 01:54:05] detectron2 INFO: Environment info:
----------------------  ---------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:51:32) [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
numpy                   1.19.5
detectron2              0.6 @/root/irg-sfda/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0+cu102 @/root/miniconda3/envs/irg_sfda/lib/python3.6/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 2080 Ti (arch=7.5)
Driver version          550.90.07
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.0+cu102 @/root/miniconda3/envs/irg_sfda/lib/python3.6/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.3
----------------------  ---------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/25 01:54:05] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sfda/sfda_foggy.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, model_dir='/root/autodl-tmp/model_final.pth', num_gpus=1, num_machines=1, opts=[], resume=False)
[02/25 01:54:05] detectron2 INFO: Contents of args.config_file=configs/sfda/sfda_foggy.yaml:
MODEL:
  META_ARCHITECTURE: "student_sfda_RCNN"
  WEIGHT: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: False
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 300
    ANCHOR_SIZES: (128, 256, 512)
  ROI_HEADS:
    NUM_CLASSES: 8
  RESNETS:
    NORM: "FrozenBN" 
    OUT_FEATURES: ["res4"]
INPUT:
  MIN_SIZE_TRAIN: (600,)
  MIN_SIZE_TEST: 600
DATASETS:
  TRAIN: ("cityscape_2007_train_t",)
  TEST: ("cityscape_2007_test_t",)
SOLVER:
  BASE_LR: 0.001
  WEIGHT_DECAY: 0.0001
  STEPS: ()
  MAX_ITER: 70000
  IMS_PER_BATCH: 1
  WARMUP_ITERS: 0
  CHECKPOINT_PERIOD: 5000
TEST:
  EVAL_PERIOD: 2000
SOURCE_FREE:
  TYPE: True
  MODE: True
  PETS:
    ENABLED: True
    EXCHANGE_PERIOD: 1
    EMA_KEEP_RATE: 0.9
    CONF_THRESH: 0.9
    IOU_THRESH: 0.5
    # BETA: 0.5
    DT_BOX_WEIGHT: 0.8
    DT_SCORE_WEIGHT: 0.8
    EPOCH_ITERS: 0
    TOTAL_EPOCHS: 5
    WARMUP_EPOCHS: 1
OUTPUT_DIR: "./checkpoint/foggy"

[02/25 01:54:05] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - cityscape_2007_test_t
  TRAIN:
  - cityscape_2007_train_t
GLOBAL:
  HACK: 1.0
INPUT:
  AUG_MODE: None
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 600
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - 128
    - 256
    - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: student_sfda_RCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 8
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 300
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./checkpoint/foggy
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 70000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  STEPS: []
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
SOURCE_FREE:
  MODE: true
  PETS:
    BETA: 0.5
    CONF_THRESH: 0.9
    DT_BOX_WEIGHT: 0.8
    DT_SCORE_WEIGHT: 0.8
    EMA_KEEP_RATE: 0.9
    ENABLED: true
    EPOCH_ITERS: 0
    EXCHANGE_PERIOD: 1
    IOU_THRESH: 0.5
    TOTAL_EPOCHS: 5
    WARMUP_EPOCHS: 1
  TYPE: true
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 2000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/25 01:54:05] detectron2 INFO: Full config saved to ./checkpoint/foggy/config.yaml
[02/25 01:54:06] d2.utils.env INFO: Using a generated random seed 6152419
[02/25 01:54:12] detectron2 INFO: Model:
student_sfda_RCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(1024, 9, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 36, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): Res5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=2048, out_features=9, bias=True)
      (bbox_pred): Linear(in_features=2048, out_features=32, bias=True)
    )
  )
  (GraphCN): GCN(
    (graph): Feat2Graph(
      (wq): Linear(in_features=2048, out_features=2048, bias=True)
      (wk): Linear(in_features=2048, out_features=2048, bias=True)
    )
    (gc1): GraphConvolution (2048 -> 512)
    (gc2): GraphConvolution (512 -> 512)
    (gc3): GraphConvolution (512 -> 2048)
  )
  (Graph_conloss): GraphConLoss(
    (head_1): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
    (head_2): Sequential(
      (0): Linear(in_features=2048, out_features=2048, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
)
[02/25 01:54:12] detectron2 INFO: Models built. Starting training...
[02/25 01:54:13] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/25 01:54:14] d2.data.build INFO: Distribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 17994        |   rider    | 1807         |    car     | 27155        |
|   truck    | 489          |    bus     | 385          |   train    | 171          |
| motorcycle | 739          |  bicycle   | 3729         |            |              |
|   total    | 52469        |            |              |            |              |[0m
[02/25 01:54:14] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7f7bb0377c88>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/25 01:54:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 01:54:14] d2.data.build INFO: Using training sampler TrainingSampler
[02/25 01:54:14] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/25 01:54:14] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/25 01:54:14] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/25 01:54:14] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mGraphCN.gc1.{bias, weight}[0m
[34mGraphCN.gc2.{bias, weight}[0m
[34mGraphCN.gc3.{bias, weight}[0m
[34mGraphCN.graph.wk.{bias, weight}[0m
[34mGraphCN.graph.wq.{bias, weight}[0m
[34mGraph_conloss.head_1.0.{bias, weight}[0m
[34mGraph_conloss.head_1.2.{bias, weight}[0m
[34mGraph_conloss.head_2.0.{bias, weight}[0m
[34mGraph_conloss.head_2.2.{bias, weight}[0m
[02/25 01:54:14] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/25 01:54:14] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /root/autodl-tmp/model_final.pth ...
[02/25 01:54:14] detectron2 INFO: Starting training from iteration 0
[02/25 01:54:15] d2.data.build INFO: Distribution of instances among all 8 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 3419         |   rider    | 556          |    car     | 4667         |
|   truck    | 93           |    bus     | 98           |   train    | 23           |
| motorcycle | 149          |  bicycle   | 1175         |            |              |
|   total    | 10180        |            |              |            |              |[0m
[02/25 01:54:15] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 01:54:15] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 01:54:15] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 01:54:15] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 01:54:54] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 01:54:54] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 01:54:54] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 01:54:54] d2.evaluation.testing INFO: copypaste: 16.1020,26.5147,16.9521
[02/25 01:54:54] detectron2 INFO: AP for person: 31.691556807863165
[02/25 01:54:54] detectron2 INFO: AP for rider: 39.16751890419787
[02/25 01:54:54] detectron2 INFO: AP for car: 36.086357171952166
[02/25 01:54:54] detectron2 INFO: AP for truck: 18.504190844616378
[02/25 01:54:54] detectron2 INFO: AP for bus: 25.324675324675326
[02/25 01:54:54] detectron2 INFO: AP for train: 9.090909090909092
[02/25 01:54:54] detectron2 INFO: AP for motorcycle: 21.10299047429387
[02/25 01:54:54] detectron2 INFO: AP for bicycle: 31.14937671330722
[02/25 01:54:55] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/25 01:54:55] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7f7c1232fc18>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/25 01:54:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 01:54:55] d2.data.build INFO: Using training sampler TrainingSampler
[02/25 01:54:55] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/25 01:54:55] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/25 02:29:06] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0002964.pth
[02/25 02:29:07] detectron2 INFO: [EPOCH 1][STUDENT] Evaluation start
[02/25 02:29:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 02:29:08] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 02:29:08] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 02:29:08] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 02:29:45] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 02:29:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 02:29:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 02:29:45] d2.evaluation.testing INFO: copypaste: 10.8945,16.8265,11.6082
[02/25 02:29:45] detectron2 INFO: AP for person: 25.459471830439572
[02/25 02:29:45] detectron2 INFO: AP for rider: 33.506378921108904
[02/25 02:29:45] detectron2 INFO: AP for car: 43.827841304276596
[02/25 02:29:45] detectron2 INFO: AP for truck: 4.545454545454546
[02/25 02:29:45] detectron2 INFO: AP for bus: 9.090909090909092
[02/25 02:29:45] detectron2 INFO: AP for train: 0.0
[02/25 02:29:45] detectron2 INFO: AP for motorcycle: 9.090909090909092
[02/25 02:29:45] detectron2 INFO: AP for bicycle: 9.090909090909092
[02/25 02:29:45] detectron2 INFO: [EPOCH 1][TEACHER] Evaluation start
[02/25 02:29:45] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 02:29:45] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 02:29:45] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 02:29:45] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 02:30:21] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 02:30:21] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 02:30:21] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 02:30:21] d2.evaluation.testing INFO: copypaste: 10.9410,17.1585,11.4037
[02/25 02:30:21] detectron2 INFO: AP for person: 25.684848484848484
[02/25 02:30:21] detectron2 INFO: AP for rider: 37.46872274816334
[02/25 02:30:21] detectron2 INFO: AP for car: 43.81147478411801
[02/25 02:30:21] detectron2 INFO: AP for truck: 3.03030303030303
[02/25 02:30:21] detectron2 INFO: AP for bus: 9.090909090909092
[02/25 02:30:21] detectron2 INFO: AP for train: 0.0
[02/25 02:30:21] detectron2 INFO: AP for motorcycle: 9.090909090909092
[02/25 02:30:21] detectron2 INFO: AP for bicycle: 9.090909090909092
[02/25 02:30:24] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/25 02:30:24] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7f7c1a952780>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/25 02:30:24] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 02:30:24] d2.data.build INFO: Using training sampler TrainingSampler
[02/25 02:30:24] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/25 02:30:24] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/25 03:04:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0005929.pth
[02/25 03:04:39] detectron2 INFO: [EPOCH 2] Refresh static teacher from student (copied 275 shared params)
[02/25 03:04:39] detectron2 INFO: [EPOCH 2][STUDENT] Evaluation start
[02/25 03:04:39] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 03:04:39] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 03:04:39] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 03:04:39] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 03:05:16] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 03:05:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 03:05:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 03:05:16] d2.evaluation.testing INFO: copypaste: 11.9447,19.2270,12.7793
[02/25 03:05:16] detectron2 INFO: AP for person: 31.156650127215123
[02/25 03:05:16] detectron2 INFO: AP for rider: 39.55680093978616
[02/25 03:05:16] detectron2 INFO: AP for car: 43.7085977316708
[02/25 03:05:16] detectron2 INFO: AP for truck: 3.03030303030303
[02/25 03:05:16] detectron2 INFO: AP for bus: 18.181818181818183
[02/25 03:05:16] detectron2 INFO: AP for train: 0.0
[02/25 03:05:16] detectron2 INFO: AP for motorcycle: 9.090909090909092
[02/25 03:05:16] detectron2 INFO: AP for bicycle: 9.090909090909092
[02/25 03:05:16] detectron2 INFO: [EPOCH 2][TEACHER] Evaluation start
[02/25 03:05:17] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 03:05:17] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 03:05:17] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 03:05:17] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 03:05:53] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 03:05:53] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 03:05:53] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 03:05:53] d2.evaluation.testing INFO: copypaste: 11.5693,18.1748,12.8886
[02/25 03:05:53] detectron2 INFO: AP for person: 30.914639037082935
[02/25 03:05:53] detectron2 INFO: AP for rider: 38.99115215411187
[02/25 03:05:53] detectron2 INFO: AP for car: 43.67416839001394
[02/25 03:05:53] detectron2 INFO: AP for truck: 4.545454545454546
[02/25 03:05:53] detectron2 INFO: AP for bus: 9.090909090909092
[02/25 03:05:53] detectron2 INFO: AP for train: 0.0
[02/25 03:05:53] detectron2 INFO: AP for motorcycle: 9.090909090909092
[02/25 03:05:53] detectron2 INFO: AP for bicycle: 9.090909090909092
[02/25 03:05:55] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/25 03:05:55] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7f7c12853e80>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/25 03:05:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 03:05:55] d2.data.build INFO: Using training sampler TrainingSampler
[02/25 03:05:55] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/25 03:05:55] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/25 03:40:08] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0008894.pth
[02/25 03:40:09] detectron2 INFO: [EPOCH 3] Refresh static teacher from student (copied 275 shared params)
[02/25 03:40:09] detectron2 INFO: [EPOCH 3][STUDENT] Evaluation start
[02/25 03:40:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 03:40:09] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 03:40:09] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 03:40:09] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 03:40:48] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 03:40:48] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 03:40:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 03:40:48] d2.evaluation.testing INFO: copypaste: 10.3412,17.9416,11.1172
[02/25 03:40:48] detectron2 INFO: AP for person: 29.846158327906114
[02/25 03:40:48] detectron2 INFO: AP for rider: 38.53216925080575
[02/25 03:40:48] detectron2 INFO: AP for car: 43.33659099525192
[02/25 03:40:48] detectron2 INFO: AP for truck: 4.545454545454546
[02/25 03:40:48] detectron2 INFO: AP for bus: 9.090909090909092
[02/25 03:40:48] detectron2 INFO: AP for train: 0.0
[02/25 03:40:48] detectron2 INFO: AP for motorcycle: 9.090909090909092
[02/25 03:40:48] detectron2 INFO: AP for bicycle: 9.090909090909092
[02/25 03:40:48] detectron2 INFO: [EPOCH 3][TEACHER] Evaluation start
[02/25 03:40:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 03:40:48] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 03:40:48] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 03:40:48] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 03:41:25] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 03:41:25] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 03:41:25] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 03:41:25] d2.evaluation.testing INFO: copypaste: 11.6971,18.1006,12.3730
[02/25 03:41:25] detectron2 INFO: AP for person: 26.102577857852587
[02/25 03:41:25] detectron2 INFO: AP for rider: 38.612518946908246
[02/25 03:41:25] detectron2 INFO: AP for car: 43.726338386472875
[02/25 03:41:25] detectron2 INFO: AP for truck: 9.090909090909092
[02/25 03:41:25] detectron2 INFO: AP for bus: 9.090909090909092
[02/25 03:41:25] detectron2 INFO: AP for train: 0.0
[02/25 03:41:25] detectron2 INFO: AP for motorcycle: 9.090909090909092
[02/25 03:41:25] detectron2 INFO: AP for bicycle: 9.090909090909092
[02/25 03:41:27] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/25 03:41:27] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7f7be1a0c2e8>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/25 03:41:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 03:41:27] d2.data.build INFO: Using training sampler TrainingSampler
[02/25 03:41:27] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/25 03:41:27] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/25 04:15:45] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0011859.pth
[02/25 04:15:46] detectron2 INFO: [EPOCH 4] Refresh static teacher from student (copied 275 shared params)
[02/25 04:15:46] detectron2 INFO: [EPOCH 4][STUDENT] Evaluation start
[02/25 04:15:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 04:15:46] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 04:15:46] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 04:15:46] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 04:16:24] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 04:16:24] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 04:16:24] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 04:16:24] d2.evaluation.testing INFO: copypaste: 6.7200,12.4495,6.1277
[02/25 04:16:24] detectron2 INFO: AP for person: 25.47470220544875
[02/25 04:16:24] detectron2 INFO: AP for rider: 32.190584275941596
[02/25 04:16:24] detectron2 INFO: AP for car: 41.930456164949305
[02/25 04:16:24] detectron2 INFO: AP for truck: 0.0
[02/25 04:16:24] detectron2 INFO: AP for bus: 0.0
[02/25 04:16:24] detectron2 INFO: AP for train: 0.0
[02/25 04:16:24] detectron2 INFO: AP for motorcycle: 0.0
[02/25 04:16:24] detectron2 INFO: AP for bicycle: 0.0
[02/25 04:16:24] detectron2 INFO: [EPOCH 4][TEACHER] Evaluation start
[02/25 04:16:24] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 04:16:24] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 04:16:24] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 04:16:24] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 04:17:03] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 04:17:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 04:17:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 04:17:03] d2.evaluation.testing INFO: copypaste: 6.4953,12.4884,6.0537
[02/25 04:17:03] detectron2 INFO: AP for person: 25.747977460669976
[02/25 04:17:03] detectron2 INFO: AP for rider: 32.36581238214852
[02/25 04:17:03] detectron2 INFO: AP for car: 41.793191299817096
[02/25 04:17:03] detectron2 INFO: AP for truck: 0.0
[02/25 04:17:03] detectron2 INFO: AP for bus: 0.0
[02/25 04:17:03] detectron2 INFO: AP for train: 0.0
[02/25 04:17:03] detectron2 INFO: AP for motorcycle: 0.0
[02/25 04:17:03] detectron2 INFO: AP for bicycle: 0.0
[02/25 04:17:05] d2.data.build INFO: Removed 0 images with no usable annotations. 2965 images left.
[02/25 04:17:05] d2.data.detection_utils INFO: Augmentations used in training: [RandomApply(
    p=0.8
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
), RandomGrayscale(p=0.2), RandomApply(
    p=0.5
    <detectron2.data.transforms.augmentation_impl.GaussianBlur object at 0x7f7ba0511cf8>
), Compose(
    ToTensor()
    RandomErasing(p=0.7, scale=(0.05, 0.2), ratio=(0.3, 3.3), value=random, inplace=False)
    RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.1, 6), value=random, inplace=False)
    RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.05, 8), value=random, inplace=False)
    ToPILImage()
)]
[02/25 04:17:05] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 04:17:05] d2.data.build INFO: Using training sampler TrainingSampler
[02/25 04:17:05] d2.data.common INFO: Serializing 2965 elements to byte tensors and concatenating them all ...
[02/25 04:17:05] d2.data.common INFO: Serialized dataset takes 4.11 MiB
[02/25 04:51:24] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_0014824.pth
[02/25 04:51:25] fvcore.common.checkpoint INFO: Saving checkpoint to ./checkpoint/foggy/model_final.pth
[02/25 04:51:26] detectron2 INFO: [EPOCH 5] Refresh static teacher from student (copied 275 shared params)
[02/25 04:51:26] detectron2 INFO: [EPOCH 5][STUDENT] Evaluation start
[02/25 04:51:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 04:51:26] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 04:51:26] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 04:51:26] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 04:52:03] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 04:52:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 04:52:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 04:52:03] d2.evaluation.testing INFO: copypaste: 5.4727,10.3636,4.9721
[02/25 04:52:03] detectron2 INFO: AP for person: 24.380147462546084
[02/25 04:52:03] detectron2 INFO: AP for rider: 17.65480895915679
[02/25 04:52:03] detectron2 INFO: AP for car: 40.87360338783631
[02/25 04:52:03] detectron2 INFO: AP for truck: 0.0
[02/25 04:52:03] detectron2 INFO: AP for bus: 0.0
[02/25 04:52:03] detectron2 INFO: AP for train: 0.0
[02/25 04:52:03] detectron2 INFO: AP for motorcycle: 0.0
[02/25 04:52:03] detectron2 INFO: AP for bicycle: 0.0
[02/25 04:52:03] detectron2 INFO: [EPOCH 5][TEACHER] Evaluation start
[02/25 04:52:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 04:52:04] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 04:52:04] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 04:52:04] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 04:52:41] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 04:52:41] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 04:52:41] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 04:52:41] d2.evaluation.testing INFO: copypaste: 6.0108,10.5812,5.3643
[02/25 04:52:41] detectron2 INFO: AP for person: 25.07570535230686
[02/25 04:52:41] detectron2 INFO: AP for rider: 17.80821917808219
[02/25 04:52:41] detectron2 INFO: AP for car: 41.76528267917975
[02/25 04:52:41] detectron2 INFO: AP for truck: 0.0
[02/25 04:52:41] detectron2 INFO: AP for bus: 0.0
[02/25 04:52:41] detectron2 INFO: AP for train: 0.0
[02/25 04:52:41] detectron2 INFO: AP for motorcycle: 0.0
[02/25 04:52:41] detectron2 INFO: AP for bicycle: 0.0
[02/25 04:52:41] detectron2 INFO: [FINAL][STUDENT] Evaluation start
[02/25 04:52:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 04:52:42] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 04:52:42] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 04:52:42] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 04:53:18] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 04:53:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 04:53:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 04:53:18] d2.evaluation.testing INFO: copypaste: 5.4727,10.3636,4.9721
[02/25 04:53:18] detectron2 INFO: AP for person: 24.380147462546084
[02/25 04:53:18] detectron2 INFO: AP for rider: 17.65480895915679
[02/25 04:53:18] detectron2 INFO: AP for car: 40.87360338783631
[02/25 04:53:18] detectron2 INFO: AP for truck: 0.0
[02/25 04:53:18] detectron2 INFO: AP for bus: 0.0
[02/25 04:53:18] detectron2 INFO: AP for train: 0.0
[02/25 04:53:18] detectron2 INFO: AP for motorcycle: 0.0
[02/25 04:53:18] detectron2 INFO: AP for bicycle: 0.0
[02/25 04:53:18] detectron2 INFO: [FINAL][TEACHER] Evaluation start
[02/25 04:53:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1333, sample_style='choice')]
[02/25 04:53:19] d2.data.common INFO: Serializing 492 elements to byte tensors and concatenating them all ...
[02/25 04:53:19] d2.data.common INFO: Serialized dataset takes 0.76 MiB
[02/25 04:53:19] d2.evaluation.evaluator INFO: Start inference on 492 batches
[02/25 04:53:55] detectron2 INFO: Evaluation results for cityscape_2007_test_t in csv format:
[02/25 04:53:55] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/25 04:53:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75
[02/25 04:53:55] d2.evaluation.testing INFO: copypaste: 6.0108,10.5812,5.3643
[02/25 04:53:55] detectron2 INFO: AP for person: 25.07570535230686
[02/25 04:53:55] detectron2 INFO: AP for rider: 17.80821917808219
[02/25 04:53:55] detectron2 INFO: AP for car: 41.76528267917975
[02/25 04:53:55] detectron2 INFO: AP for truck: 0.0
[02/25 04:53:55] detectron2 INFO: AP for bus: 0.0
[02/25 04:53:55] detectron2 INFO: AP for train: 0.0
[02/25 04:53:55] detectron2 INFO: AP for motorcycle: 0.0
[02/25 04:53:55] detectron2 INFO: AP for bicycle: 0.0
